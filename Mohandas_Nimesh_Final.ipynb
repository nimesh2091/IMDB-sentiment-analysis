{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Git-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import imdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "88585\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of words\n",
    "print(\"Number of words: \")\n",
    "print(len(np.unique(np.hstack(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2dc9ac0f5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize review length\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "# plot review length\n",
    "plt.boxplot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "seed = 101\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 31s 1ms/step - loss: 0.5075 - acc: 0.7113\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.1912 - acc: 0.9269\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.0592 - acc: 0.9828\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.0110 - acc: 0.9985\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.0024 - acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dcb1508e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.54%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing number of epochs as the model is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 31s 1ms/step - loss: 0.4619 - acc: 0.7535\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.1712 - acc: 0.9358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dc9b11f0b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.69%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, after the Embedding input layer, we insert a Conv1D layer. This convolutional layer has 32 feature maps and reads embedded word representations 3 vector elements of the word embedding at a time.The convolutional layer is followed by a 1D max pooling layer with a length and stride of 2 that halves the size of the feature maps from the convolutional layer. The rest of the network is the same as the neural network above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.4414 - acc: 0.7651\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.2132 - acc: 0.9159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dc9fa005f8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.38%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, batch_size=128,verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one hidden layer to the above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 126       \n",
      "=================================================================\n",
      "Total params: 2,194,855\n",
      "Trainable params: 2,194,855\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 34s 1ms/step - loss: 0.4446 - acc: 0.7616\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.2089 - acc: 0.9184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dca3419e48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.37%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since accuracy has dropped, removing hidden layer and proceeding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing batch size to check if the accuracy is improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.5365 - acc: 0.7090\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.2425 - acc: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dca748ccf8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 2, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.73%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, batch_size=300, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sticking to batch size 300 which is giving higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.6682 - acc: 0.5848\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.2994 - acc: 0.8766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dca84dfdd8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 2, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.50%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, batch_size=300, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
